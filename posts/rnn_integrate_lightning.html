<!doctype html>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        <title>Crisp Blog</title>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" type="text/css" href="../css/slim.css" />
        <link rel="stylesheet" type="text/css" href="../css/style.css" />
        <link rel="stylesheet" type="text/css" href="../css/syntax.css" />
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@300..700&display=swap" rel="stylesheet">
    </head>

    <body>
    <div class="container">
        <div class="header">
            <h1 class="site-title"><a href="../">Crisp Blog</a></h1>
            <div class="nav">
                <a class="nav-btn" href="#">
                    <span class="ci ci-burger"></span>
                </a>
                <ul class="nav-list">
                    
                    <li class="spacer">∾</li>
                    <li><a href="../">Home</a></li>
                    <li><a href="../projects.html">Projects</a></li>
                    <li><a href="mailto:bodw3@qq.com">Contact</a></li>
                </ul>
            </div>
        </div>


        <div class="content">
            <div class="post">
    <h1 class="post-title"><a href>如何使用pytorch_lightning搭建RNN模型以及实现经典单块模拟</a></h1>
    <div class="post-date">July 28, 2024</div>

    <div class="post-content">
        <p>如果你想了解如何使用神经网络对单块、箱头等吉他周边进行模拟，Alec Wright的论文<a href="https://acris.aalto.fi/ws/portalfiles/portal/36768418/ELEC_Wright_Real_time_black_box_DAFx2019.pdf">REAL-TIME BLACK-BOX MODELLING WITH RECURRENT NEURAL NETWORKS</a>是一个很好的开始。首先，作者Alec没有使用很复杂的模型即完成了不错的模拟。其次，作者开源了相应的模型代码<a href="https://github.com/Alec-Wright/Automated-GuitarAmpModelling">Automated-GuitarAmpModelling</a>，其中包含完整的训练流程以及数据集，极大地降低了学习成本。</p>
<p>本文可以看作是对论文以及对应项目的学习笔记，因此文中会大量借鉴论文中的想法和项目中的实现。除此之外，本文会尝试将原项目移植到<a href="https://lightning.ai/docs/pytorch/stable/">Pytorch Lightning</a>框架中。运用Pytorch Lightning的特性，可为计算资源的调用提供灵活性以及减少重复造轮子的成本。</p>
<div>

</div>
<!--more-->
<h1 id="什么是循环神经网络rnn">什么是循环神经网络（RNN）</h1>
<p>不同于前馈神经网络（比如卷积神经网络），循环神经网络的输入部分，除了当前的数据内容，还需要输入之前的状态信息。也就是说，循环神经网络每一次处理数据时，会生成当前状态信息，以供下一次处理数据时使用。下面是一个RNN单元的示例：</p>
<p><img src="../images/rnn/rnn_unit.png" style="width:50.0%" /></p>
<p>可以看到，一个RNN单元接收两个输入，x[n]为当前的数据，h[n-1]为上一次状态信息。其处理后产生的两个输出，y[n]作为输出结果，h[n]作为当前状态信息，给下一次处理使用。h被称为hidden state。</p>
<p>接着，当该RNN单元处理x[n+1]时有以下流程（注意关联上下两图的红色部分）：</p>
<p><img src="../images/rnn/rnn_unit-2.png" style="width:50.0%" /></p>
<p>至于RNN单元内部做了哪些处理，不同的RNN类型有各自的做法。常见的RNN层有LSTM(Long Short-Term Memory)以及GRU(Gated Recurrent Unit)。下面简单介绍一下GRU的流程。</p>
<h2 id="gru">GRU</h2>
<p><img src="../images/rnn/gru.png" style="width:50.0%" /></p>
<p>可以看到，GRU直接使用h[n]作为结果输出以及状态信息。h[n]的生成遵循下面的公式：</p>
<div class="special-formula">
<p><span class="math inline">\(z[n] = \sigma(W_z x[n] + U_z h[n-1])\)</span></p>
<p><span class="math inline">\(r[n] = \sigma(W_r x[n] + U_r h[n-1])\)</span></p>
<p><span class="math inline">\(\tilde{h}[n] = tanh(W_h x[n] + U_h (r[n] \ast h[n-1]))\)</span></p>
<p><span class="math inline">\(h[n] = (1 - z[n]) \ast \tilde{h}[n] + z[n] \ast h[n-1]\)</span></p>
</div>
<p>其中，W和U为需要训练的权重。z为update gate，r为reset gate。</p>
<p>神经元的规模受输入数据的尺寸和hidden size的影响。hidden size还用于指定hidden state的规模。</p>
<p>关于GRU的更多细节，这里不再赘述。</p>
<h1 id="模型以及训练方法">模型以及训练方法</h1>
<h2 id="模型介绍">模型介绍</h2>
<p>论文中使用的模型十分简明，如下所示：</p>
<p><img src="../images/rnn/model_review.png" style="width:40.0%" /></p>
<p>可以看到，模型包含两层，先是GRU，再是一个全连接层。</p>
<p>不考虑batch的情况下，数据维度为(seq_len, 1)，其中seq_len为序列长度。也就是说，我们所处理的数字音频信号，其采样点个数即为seq_len。</p>
<p>于是，我们很容易实现模型的初始化和forward部分。</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RNNModel(nn.Module):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_size <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_size <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rec <span class="op">=</span> nn.GRU(</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                        input_size <span class="op">=</span> <span class="va">self</span>.input_size,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                        hidden_size <span class="op">=</span> <span class="va">self</span>.hidden_size,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                   )</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lin <span class="op">=</span> nn.Linear(<span class="va">self</span>.hidden_size, <span class="va">self</span>.output_size)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        x, <span class="va">self</span>.hidden <span class="op">=</span> <span class="va">self</span>.rec(x, <span class="va">self</span>.hidden)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.lin(x)</span></code></pre></div>
<h2 id="如何训练">如何训练</h2>
<p>在阐述RNN的训练流程之前，我们先来看前馈神经网络的训练流程，然后说明其训练为何不能直接套用到RNN上。</p>
<p>我们以经典的MNIST图像识别为例，该数据集为上万张黑白图片，尺寸为28x28，每张图片为手写的阿拉伯数字0-9。</p>
<p>模型输入的最小单位是一个28x28的矩阵，模型输出尺寸为10的向量。不考虑batch的情况下，每处理一张图片做一次反向传播。</p>
<p>我们再来看当前场景的RNN模型，其输入的最小单位是一个采样点，即一个值，模型随后输出另一个值。可以想象，若每处理一个采样点就做一次反向传播是不可取的。第一，带来巨大的计算开销；第二，在一般的RNN模型中，一个采样点不仅要参与到对下一个time step的预测，还需要参与多个time step之后的某个值的预测，因此只通过后一个time step的信息来进行学习是无法完成这类任务的。</p>
<p>因此，在RNN的训练中，有一个名为Back-Propagation Through Time(BPTT)的基本概念，其意思为每处理一段完整的序列，才做一次反向传播。但是，这里又会引入一个新的问题，为了达到较好的预测效果，完整的序列通常不会很短，这就会导致反向传播构造出的计算图非常大，由此带来计算开销的问题。为了解决这个问题，我们使用BPTT的一个改进: Truncated Back-Propagation Through Time。</p>
<h3 id="truncated-back-propagation-through-time">Truncated Back-Propagation Through Time</h3>
<p>该方法的思路很简单，相比于BPTT中一段完整的序列做一次反向传播，该方法则将完整的序列拆分为连续的子序列，一段子序列做一次反向传播。</p>
<p>但是，该方法不改动子序列之间的关联性，即每个子序列的hidden state不进行重置，而是继承上一次子序列输出的hidden state。</p>
<p>此外，为了避免重复计算梯度，每个子序列处理之后，hidden state需要做detach。</p>
<p>下面通过代码展示该流程，代码来自对<a href="https://github.com/Alec-Wright/Automated-GuitarAmpModelling">Automated-GuitarAmpModelling</a>中相关部分的改写。为了方便阐述，代码做了一定简化。</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 基于前述的RNNModel，增加以下成员函数detach_hidden(...), reset_hidden(...)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RNNModel(nn.Module):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ...</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> detach_hidden(<span class="va">self</span>):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> <span class="va">self</span>.hidden.clone().detach()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reset_hidden(<span class="va">self</span>):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> <span class="va">None</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 下面是RNNModel的训练流程，部分参数含义：</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#   - EPOCH_NUM: epoch的次数</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#   - train_dataset: 数据集，由batch组成的list</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     - 其中，batch的形式为(输入数据, 标签数据)。输入和标签数据的形式为(序列长度, batch大小，采样点的维度)</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#   - SEG_LEN: 子序列的长度</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">#   - loss_func: 损失函数</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">#   - optimizer: 优化器</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RNNModel()</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(EPOCH_NUM):</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ...</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> train_dataset:</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> batch <span class="co"># 得到输入数据和标签数据</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        seg_start_i <span class="op">=</span> <span class="dv">0</span> <span class="co"># 子序列的起点</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(math.ceil(x.shape[<span class="dv">0</span>] <span class="op">/</span> SEG_LEN)):</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>            seg_end_i <span class="op">=</span> seg_start_i <span class="op">+</span> SEG_LEN <span class="co"># 子序列的终点</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> model(x[seg_start_i:seg_end_i, :, :]) <span class="co"># 从输入数据中获取子序列，输入模型做forward</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 做误差计算和反向传播</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_func(logits, y[seg_start_i:seg_end_i, :, :])</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>            model.zero_grad()</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 将模型的hidden state进行detach，防止后续梯度重复计算</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>            model.detach_hidden()</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 起点指向下一个子序列开头</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>            seg_start_i <span class="op">+=</span> SEG_LEN</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 完整序列处理完毕，重置hidden state</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>        model.reset_hidden()</span></code></pre></div>
<h2 id="损失函数链">损失函数链</h2>
<p>对于数字信号的误差计算，一般会用到ESR(Error-to-Signal Ratio)。在此基础上为了得到更好的训练效果，还会有高频补偿的预处理以及直流修正等损失函数的参与。</p>
<h3 id="高频补偿形式的esr">高频补偿形式的ESR</h3>
<p>面对音频相关模型的训练时，许多论文都会指出模型对于高频部分的训练效果不佳。一个常见的解决方法就是在ESR之前对输出数据和标签数据做高通滤波。</p>
<p>该论文在损失函数介绍部分（4.1. LossFunction）中，提及的”pre-emphasis filter”即是此意。这是一个一阶高通滤波器，形式如下：</p>
<div class="special-formula">
<span class="math inline">\(H(z) = 1 - 0.85z^{-1}\)</span>
</div>
<p>经过滤波后的数据再经过ESR得到误差结果，下面是ESR的公式：</p>
<div class="special-formula">
<span class="math inline">\(\varepsilon_{ESR} = \frac{\sum_{n=0}^{N-1} |y_p[n] - \hat{y}_p[n]|^2}{\sum_{n=0}^{N-1} |y_p[n]|^2}\)</span>
</div>
<p>其中，<span class="math inline">\(y_p[n]\)</span>为标签数据，<span class="math inline">\(\hat{y}_p[n]\)</span>为模型输出数据。</p>
<p>可以看到，分子部分通过比较输出数据和标签数据每个time step的差值得到误差能量并求和。而分母部分为标签数据对应的能量，这是一种让能量归一化的做法，保证能量不同的片段在损失函数中被同等对待。</p>
<h3 id="直流修正">直流修正</h3>
<p>引入直流修正的原因在于论文作者发现模型训练出来的结果会产生额外的直流分量。因此，作者在论文中介绍了一个DC Loss损失函数，如下所示：</p>
<div class="special-formula">
<span class="math inline">\(\varepsilon_{DC} = \frac{|\frac{1}{N}\sum_{n=0}^{N-1}(y[n] - \hat{y}[n])|^2}{\frac{1}{N}\sum_{n=0}^{N-1} |y[n]|^2}\)</span>
</div>
<p>这个公式和ESR的区别在于，ESR是对每个time step求差值的能量再求和。DC Loss则是对序列的所有的time step得出的平均差值再求能量。也就是说，DC Loss认为，数据的直流特征可以通过整段数据的平均值进行表达。</p>
<h3 id="损失函数的协调">损失函数的协调</h3>
<p>在计算误差时，多个损失函数结果会进行加权求和作为最终的误差。</p>
<!--div class="special-formula">$\varepsilon = \omega {Pre-Emph_ESR} + $</div-->
<div class="special-formula">
<span class="math inline">\(\varepsilon = \sum_{i}{\omega_i\varepsilon_i}\)</span>
</div>
<h1 id="利用pytorch-lightning训练rnn">利用Pytorch Lightning训练RNN</h1>
<p>我们知道，即使是不同的模型，其数据集的处理和整个训练流程都包含许多通用的步骤，比如反向传播的流程、运算资源的指定、日志的收集等。这些步骤有的繁琐，有的对执行顺序有严格的要求。如果每次遇见新的模型都要自己操手这些流程，会极大地影响实现的效率，并且维护起来也十分不便。</p>
<p><a href="https://lightning.ai/docs/pytorch/stable/">Pytorch Lightning</a>即为解决这个问题而生。这个框架会接手大部分通用的流程，比如，训练过程中不用关心数据和模型是否在对应的device上，lightning会依据配置完成关联；对于模型在train状态还是eval状态，由lightning负责；梯度计算、反向传播、梯度重置的工作，默认由lightning负责。</p>
<p>下面以一个简单的前馈神经网络为例：</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytorch_lightning <span class="im">as</span> pl</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Model(pl.LightningModule):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l1 <span class="op">=</span> nn.Linear(<span class="dv">100</span>, <span class="dv">64</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l2 <span class="op">=</span> nn.Linear(<span class="dv">64</span>, <span class="dv">10</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        h1 <span class="op">=</span> nn.functional.relu(<span class="va">self</span>.l1(x))</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.functional.relu(<span class="va">self</span>.l2(h1))</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 配置optimizer</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> configure_optimizers(<span class="va">self</span>):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> optim.SGD(<span class="va">self</span>.parameters(), lr<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> optimizer</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> training_step(<span class="va">self</span>, batch, batch_idx):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> batch</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>(x) <span class="co"># forward</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        J <span class="op">=</span> nn.CrossEntropyLoss(logits, y) <span class="co"># 算误差</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> J</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 配置数据集</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_dataloader(<span class="va">self</span>):</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model()</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> pl.Trainer(max_epochs<span class="op">=</span><span class="dv">1000</span>, accelerator<span class="op">=</span><span class="st">&quot;gpu&quot;</span>, devices<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>trainer.fit(model)</span></code></pre></div>
<p>可以看到，我们只需要在training_step(…)中完成forward流程和损失函数调用部分，其他部分由lightning接管即可。</p>
<p>当然，lightning的默认流程并不能涵盖所有的场景，因此lightning也通过丰富的hook来给模型训练流程的定制提供足够的灵活性。</p>
<p>例如前面提及的Truncated Back-Propagation Through Time方法是lightning的默认流程无法满足的，我们需要自己接管子序列的反向传播流程。</p>
<p>下面，我们尝试将上述的RNNModel代码改写为lightning形式，如下：</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytorch_lightning <span class="im">as</span> pl</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RNNModel(pl.LightningModule):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up_fr <span class="op">=</span> up_fr</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.automatic_optimization <span class="op">=</span> <span class="va">False</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> configure_optimizers(<span class="va">self</span>):</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(<span class="va">self</span>.parameters(), lr<span class="op">=</span><span class="fl">0.005</span>, weight_decay<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> optimizer</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> training_step(<span class="va">self</span>, batch, batch_idx):</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> batch</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        opt <span class="op">=</span> <span class="va">self</span>.optimizers() <span class="co"># 获得优化器</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        seg_start_i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(math.ceil(x.shape[<span class="dv">0</span>] <span class="op">/</span> <span class="va">self</span>.up_fr)):</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            seg_end_i <span class="op">=</span> seg_start_i <span class="op">+</span> <span class="va">self</span>.up_fr</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> <span class="va">self</span>(x[seg_start_i:seg_end_i, :, :])</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="va">self</span>.loss_func(logits, y[seg_start_i:seg_end_i, :, :]) <span class="co"># 上文提及的损失函数链</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># self.automatic_optimization为False时，lightning不会自动执行backward、step和zero_grad这三个流程。我们自行调用，即下面三行。</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.manual_backward(loss)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>            opt.step()</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>            opt.zero_grad()</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.detach_hidden()</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>            seg_start_i <span class="op">+=</span> <span class="va">self</span>.up_fr</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reset_hidden()</span></code></pre></div>
<p>RNNModel原先继承nn.Module改为pl.LightningModule。由于pl.LightningModule完全包含nn.Module的功能，可完全替代之。</p>
<p>然后，之前对RNNModel的训练流程在这里的training_step(…)中体现。在该函数中，我们自行决定对backward、step和zero_grad的执行，而不希望lightning参与。为了实现这一点，需要对self.automatic_optimization进行设置。</p>
<p>self.automatic_optimization默认为True，此时lightning会根据training_step(…)返回的误差自动进行backward、step和zero_grad。而这里我们设置为False，即我们自己接管这三个流程的执行。</p>
<p>此外，需要注意上述的数据形式为（序列长度, batch大小，采样点的维度），这保证与nn.GRU的默认输入数据要求一致。若原数据形式为（batch大小，序列长度，采样点的维度），在forward前可通过以下操作调整形式：</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RNNModel(pl.LightningModule):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ...</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> training_step(<span class="va">self</span>, batch, batch_idx):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> batch</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.movedim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> y.movedim(<span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<h2 id="训练结果">训练结果</h2>
<p>训练数据方面，我们使用<a href="https://github.com/Alec-Wright/Automated-GuitarAmpModelling">Automated-GuitarAmpModelling</a>项目提供的数据集，并使用其中的ht1设备的数据。ht1即黑星HT-1电子管。</p>
<p>模型参数方面，我们使用hidden size为32的GRU进行训练。训练中，epochs设为500次，我们取其中validation loss最低的模型参数作为最终参数。</p>
<p>经过多轮训练，我们的模型的ESR结果大约在2.5%左右，和论文中的3.3%在同一数量级。</p>
<p>以下我们摘取标签数据和实际模型输出数据的片段进行对比：</p>
<figure>
<audio controls>
<source src="../embeds/target-clip.wav" type="audio/wav">
Your browser does not support the audio element.
</audio>
<figcaption>
标签片段
</figcaption>
</figure>
<figure>
<audio controls>
<source src="../embeds/pre_esr-clip.wav" type="audio/wav">
Your browser does not support the audio element.
</audio>
<figcaption>
模型输出片段
</figcaption>
</figure>
<p>可以听到，经过训练后模型学习到了大部分的风味，不过仍然有一些细节是缺失的，尤其是高频部分。为了得到更接近的结果，可能需要引入更复杂的模型，这是之后的一个探索方向。</p>
    </div>
</div>
        </div>

        <hr>
        <div class="footer">
            <p>Powered by <a href="http://jaspervdj.be/hakyll">Hakyll</a>. Style from <a href="https://github.com/travisbrown/metaplasm">metaplasm</a> & <a href="https://github.com/zhe/hugo-theme-slim">slim</a>.</p>
        </div>

    
    </div>
    
    <script src="../js/slim.js"></script>

    </body>

</html>
